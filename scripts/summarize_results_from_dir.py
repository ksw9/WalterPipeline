#!/usr/bin/env python3

"""
This script parses the reports generated by TrimGalore, Kraken2, BWA/Bowtie2, and TbProfiler and generates a single coherent report
Equivalent to make_run_summary.py, but designed to be run manually after the Nextflow pipeline
"""

### ---------------------------------------- ###

def parseTrimGaloreReport(report_name):
    
    report = open(report_name).read().split('\n')
    
    raw_reads = [int(line.split(' ')[-1].replace(',', '')) for line in report if 'Total reads processed:' in line][0]
    reads_with_adapters = [int(line.split(' ')[-2].replace(',', '')) for line in report if 'Reads with adapters:' in line][0]
    trimmed_reads = [int(line.split(' ')[-2].replace(',', '')) for line in report if 'Reads written (passing filters):' in line][0]
    
    return raw_reads, reads_with_adapters, trimmed_reads

### ---------------------------------------- ###

def parseKraken2Report(report_name):
    
    report = open(report_name).read().split('\n')
    
    kraken_tb_reads = [int(line.split('\t')[1].replace(',', '')) for line in report if 'Mycobacterium tuberculosis complex' in line][0]
    
    return kraken_tb_reads

### ---------------------------------------- ###

def parseMappingReport(report_name):
    
    report = open(report_name).read().split('\n')
    
    mapping_percentage = [float(line.split(' ')[-1][1:-1].split('%')[0]) for line in report if 'properly paired' in line][0]
    
    return mapping_percentage

### ---------------------------------------- ###

def parseDuplicationReport(report_name):
    
    _, header, dup_data = [block for block in open(report_name).read().split('\n\n') if '## METRICS CLASS\tpicard.sam.DuplicationMetrics' in block][0].split('\n')
    
    percent_duplication = float(dup_data.split('\t')[header.split('\t').index('PERCENT_DUPLICATION')])
    
    return percent_duplication

### ---------------------------------------- ###

def parseCoverageReport(report_name):
    
    _, metrics_header, metrics = [block for block in open(report_name).read().split('\n\n') if '## METRICS' in block][0].split('\n')
    histogram = [block for block in open(report_name).read().split('\n\n') if '## HISTOGRAM' in block][0].split('\n')[1:]
    histogram = [[int(n) for n in line.split('\t')] for line in histogram[1:]]
    
    mean_coverage, median_coverage, sd_coverage = [float(metrics.split('\t')[metrics_header.split('\t').index(h)]) for h in ['MEAN_COVERAGE', 'MEDIAN_COVERAGE', 'SD_COVERAGE']]
    
    sum_cov = sum([h[1] for h in histogram])
    
    cov_5 = 100 * [h[1] for h in histogram if h[0] == 5][0] / sum_cov
    cov_10 = 100 * [h[1] for h in histogram if h[0] == 10][0] / sum_cov
    cov_100_plus = 100 * sum([h[1] for h in histogram if h[0] >= 100]) / sum_cov
    
    return mean_coverage, median_coverage, sd_coverage, cov_5, cov_10, cov_100_plus

### ---------------------------------------- ###

def parseResistanceReport(report_name):
    
    summary_section = [block for block in open(report_name).read().split('\n\n') if 'Summary\n---' in block][0].split('\n')
    #resistance_report = [block for block in open(report_name).read().split('\n\n') if 'Resistance report\n---' in block][0].split('\n')[3:]
    
    strain, drug_resistance = [line.split(',')[1] for line in summary_section for field in ['Strain', 'Drug-resistance'] if field in line]
    strain = strain if strain != '' else 'NA'
    
    return strain, drug_resistance

### ------------------MAIN------------------ ###

from datetime import datetime
from os import listdir
from os.path import isdir
from sys import argv

### PARSE DATA ----------------------------- ###

# Import reads/sample list file name
results_dir = argv[argv.index("--results_dir") + 1]

# Init summary report
summary_header = ["Sample",
                  "Batch",
                  "Raw_Reads",
                  "Raw_Reads_With_Adapters",
                  "Trimmed_Raw_Reads",
                  "Kraken2_Raw_Reads",
                  "Mapping_Percentage",
                  "Duplication_Percentage",
                  "Coverage_Mean",
                  "Coverage_Median",
                  "Coverage_SD",
                  "Coverage_5_Percentage",
                  "Coverage_10_Percentage",
                  "Coverage_100+_Percentage",
                  "Strain",
                  "Drug_Resistance"]
summary = {h : [] for h in summary_header}

# Make list of (batch, sample) info
data = [(batch, sample) for batch in listdir(results_dir) if isdir(f'{results_dir}/{batch}') for sample in listdir(f'{results_dir}/{batch}') if isdir(f'{results_dir}/{batch}/{sample}')]

# Parse data for each sample specified in reads_list
for (batch, sample) in data:
    
    # Basic info
    summary['Sample'].append(sample)
    summary['Batch'].append(batch)
    
    # Parse R1 TrimGalore report
    try:

        trimming_report = [f'{results_dir}/{batch}/{sample}/trim/{file}' for file in listdir(f'{results_dir}/{batch}/{sample}/trim/') if file.endswith('trimming_report.txt')][0]
        raw_reads, reads_with_adapters, trimmed_reads = parseTrimGaloreReport(trimming_report)
    
    except:

        raw_reads, reads_with_adapters, trimmed_reads = 'NA', 'NA', 'NA'

    summary['Raw_Reads'].append(raw_reads)
    summary['Raw_Reads_With_Adapters'].append(reads_with_adapters)
    summary['Trimmed_Raw_Reads'].append(trimmed_reads)
    
    # Parse info from Kraken2 report
    try:

        raw_reads = parseKraken2Report(f'{results_dir}/{batch}/{sample}/kraken/{sample}_kraken.report')
    
    except:

        raw_reads = 'NA'

    summary['Kraken2_Raw_Reads'].append(raw_reads)
    
    # Parse mapping info
    try:

        percentage_mapped_reads = parseMappingReport(f'{results_dir}/{batch}/{sample}/stats/{sample}_mapping.log')

    except:

        percentage_mapped_reads = 'NA'

    summary['Mapping_Percentage'].append(percentage_mapped_reads)
    
    # Parse duplication info
    try:

        duplication_percentage = parseDuplicationReport(f'{results_dir}/{batch}/{sample}/stats/{sample}_marked_dup_metrics.txt')
    except:

        duplication_percentage = 'NA'

    summary['Duplication_Percentage'].append(duplication_percentage)
    
    # Parse coverage info
    try:

        mean, median, sd, cov_5, cov_10, cov_100_plus = parseCoverageReport(f'{results_dir}/{batch}/{sample}/stats/{sample}_coverage_stats.txt')

    except:

        mean, median, sd, cov_5, cov_10, cov_100_plus = 'NA', 'NA', 'NA', 'NA', 'NA', 'NA'

    summary['Coverage_Mean'].append(mean)
    summary['Coverage_Median'].append(median)
    summary['Coverage_SD'].append(sd)
    summary['Coverage_5_Percentage'].append(cov_5)
    summary['Coverage_10_Percentage'].append(cov_10)
    summary['Coverage_100+_Percentage'].append(cov_100_plus)

    # Parse Tb-Profiler report
    try:

        strain, drug_resistance = parseResistanceReport(f'{results_dir}/{batch}/{sample}/stats/{sample}_lineageSpo_gatk.csv')

    except:

        strain, drug_resistance = 'NA', 'NA'

    summary['Strain'].append(strain)
    summary['Drug_Resistance'].append(drug_resistance)

### EXPORT DATA ---------------------------- ###

# Formatting text
summary_text = '\n'.join(['\t'.join(summary_header)] +
                         ['\t'.join([str(summary[h][i]) for h in summary_header]) for i in range(len(summary['Sample']))])

# Saving to tsv
with open(f'results_summary_{str(datetime.now()).replace(" ", "_").replace(":", "-")}.tsv', 'w') as summary_out:
    
    summary_out.write(summary_text)
